{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 45) (500, 1)\n",
      "(400, 45) (400, 1)\n",
      "(100, 45) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from logistic_regression.GrdDscntQuant import grdescentquant\n",
    "from logistic_regression.normal_logistic import normallogistic\n",
    "from logistic_regression.GrdDscnt import grdescentnormal\n",
    "from logistic_regression.quant_logistic import quant_logistic\n",
    "from logistic_regression.GrdDscntUncoded import grdescentuncoded\n",
    "from logistic_regression.uncoded_logistic import  uncoded_logistic\n",
    "from quantization.quantize import quantize\n",
    "from coded_computation.master import master\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from pad_and_clean import pad\n",
    "from pad_and_clean import clean_and_scale\n",
    "import time\n",
    "from gen_data import gen_data, gen_nonlinear_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_loss(w,X,y):\n",
    "    #calculates 1-0 prediction error\n",
    "    log_odds = X@w\n",
    "    probs = 1 / (1 + np.exp(-log_odds))\n",
    "    preds = np.where(probs > 0.5, 1,-1)\n",
    "    test_loss = np.mean(preds != y)\n",
    "\n",
    "    return test_loss\n",
    "def plot_3d_bar(data, z):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Define the x, y coordinates and the z heights\n",
    "    _x = np.arange(data.shape[1])\n",
    "    _y = np.arange(data.shape[0])\n",
    "    _x, _y = np.meshgrid(_x, _y)\n",
    "    x, y = _x.ravel(), _y.ravel()\n",
    "\n",
    "    # The z values represent the bar heights\n",
    "    z = np.zeros_like(x)\n",
    "    dz = data.ravel()\n",
    "\n",
    "    # Plot 3D bars\n",
    "    ax.bar3d(x, y, z, 1, 1, dz, shade=True)\n",
    "\n",
    "    # Labels\n",
    "    ax.set_xlabel('w_lvl')\n",
    "    ax.set_ylabel('grd_lvl')\n",
    "    ax.set_zlabel(z)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def run(X,y, filename):\n",
    "    func = quant_logistic\n",
    "    G = np.array([\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [-1, -1, -1, 1, 1, 1, 1],\n",
    "        [-1, 1, 1, -1, -1, 1, 1],\n",
    "        [1, -1, -1, -1, -1, 1, 1],\n",
    "        [1, -1, 1, -1, 1, -1, 1],\n",
    "        [-1, 1, -1, -1, 1, -1, 1],\n",
    "        [-1, -1, 1, 1, -1, -1, 1],\n",
    "        [1, 1, -1, 1, -1, -1, 1]\n",
    "    ]).T\n",
    "\n",
    "    stepsize = 0.1\n",
    "    maxiter = 10000\n",
    "\n",
    "    #X,y = gen_nonlinear_data(500, 40, 1)\n",
    "\n",
    "    X, Xt, y, yt = train_test_split(X, y, test_size=0.2)\n",
    "    X, y = pad(X, y, 7)\n",
    "    Xt, yt = pad(Xt, yt, 7)\n",
    "\n",
    "    Master_uncoded = master(X, None, 21)\n",
    "    Master = master(X, G, 3)\n",
    "    times_grid = np.zeros((5, 4))\n",
    "    loss_grid = np.zeros((5, 4))  # Initialize for each dataset\n",
    "    iters_grid = np.zeros((5, 4))\n",
    "    test_loss = np.zeros((5, 4))\n",
    "    test_loss_uncoded = np.zeros((5,4))\n",
    "    uncoded_times = np.zeros((5, 4))\n",
    "    # loss from normal logistic regression\n",
    "    w0 = np.random.uniform(-1, 1, (X.shape[1], 1))\n",
    "    start_time = time.time()\n",
    "    w, num_iters = grdescentnormal(normallogistic, w0, stepsize, maxiter, Master_uncoded, y, X, tolerance=1e-02)\n",
    "    normal_loss = get_loss(w, Xt, yt)\n",
    "    end_time = time.time()\n",
    "    print(f\"loss from unquantized logistic regresison: {normal_loss} on {num_iters} iterations in {end_time - start_time} seconds\")\n",
    "    repetitions = 100\n",
    "    for i in range(repetitions):\n",
    "        for w_lvl in range(4, 9):\n",
    "            for grd_lvl in range(2, 6):\n",
    "                # logic for calculations\n",
    "                w0 = np.random.uniform(-1, 1, (X.shape[1], 1))\n",
    "\n",
    "                start_time = time.time()\n",
    "                #w, num_iters = grdescentquant(func, w0, stepsize, maxiter, Master, w_lvl, grd_lvl, X, y, filename, tolerance=1e-02)\n",
    "                w, num_iters = grdescentquant(func, w0, stepsize, maxiter, Master, w_lvl, grd_lvl, X, y, filename, 1e-02)\n",
    "                # grdescentquant(func, w, stepsize, maxiter, Master, w_lvl, grd_lvl, X, y, filename, tolerance)\n",
    "\n",
    "                end_time = time.time()\n",
    "\n",
    "                times_grid[w_lvl - 4, grd_lvl - 2] += end_time - start_time\n",
    "                loss_grid[w_lvl - 4, grd_lvl - 2] += get_loss(w, X, y)\n",
    "                iters_grid[w_lvl - 4, grd_lvl - 2] += num_iters\n",
    "                test_loss[w_lvl - 4, grd_lvl - 2] += get_loss(w, Xt, yt)\n",
    "\n",
    "                start_time = time.time()\n",
    "                w, num_iters = grdescentuncoded(uncoded_logistic, w0, stepsize, maxiter, Master_uncoded, w_lvl, grd_lvl, X, y, tolerance=1e-02)\n",
    "                end_time = time.time()\n",
    "                uncoded_times[w_lvl - 4, grd_lvl - 2] += end_time - start_time\n",
    "                test_loss_uncoded[w_lvl - 4, grd_lvl - 2] += get_loss(w,Xt,yt)\n",
    "\n",
    "    test_loss = test_loss/repetitions\n",
    "    loss_grid = loss_grid/repetitions\n",
    "    iters_grid = iters_grid/repetitions\n",
    "    times_grid = times_grid/repetitions\n",
    "    test_loss_uncoded = test_loss_uncoded/repetitions\n",
    "    uncoded_times = uncoded_times/repetitions\n",
    "\n",
    "\n",
    "\n",
    "    print(f\" training loss: \\n{loss_grid}\")\n",
    "    print(f\" avg iterations: \\n{iters_grid}\")\n",
    "    print(f\" test loss: \\n{test_loss}\")\n",
    "    print(f\"run time: \\n{times_grid}\")\n",
    "    print(f\" test loss uncoded: \\n{test_loss_uncoded}\")\n",
    "    print(f\" times uncoded: \\n{uncoded_times}\")\n",
    "    return test_loss, loss_grid, iters_grid, times_grid, test_loss_uncoded, uncoded_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from unquantized logistic regresison: 0.37142857142857144 on 394 iterations in 0.08082318305969238 seconds\n",
      "response, actual \n",
      " [[27.71681189  1.46413096]\n",
      " [19.80796433  2.46779736]\n",
      " [-0.0863594  -1.70987823]\n",
      " [ 5.82709958 -1.47425213]\n",
      " [47.02534799  3.24531103]] \n",
      "\n",
      "index passed: [[-0.37851602]\n",
      " [-0.37542618]\n",
      " [-0.37233634]\n",
      " [-0.3692465 ]\n",
      " [-0.36615666]\n",
      " [-0.36306682]\n",
      " [-0.35997698]\n",
      " [-0.35688714]\n",
      " [-0.3537973 ]\n",
      " [-0.35070746]\n",
      " [-0.34761762]\n",
      " [-0.34452778]\n",
      " [-0.34143794]\n",
      " [-0.3383481 ]\n",
      " [-0.33525826]\n",
      " [-0.33216843]\n",
      " [-0.32907859]\n",
      " [-0.32598875]\n",
      " [-0.32289891]\n",
      " [-0.31980907]\n",
      " [-0.31671923]\n",
      " [-0.31362939]\n",
      " [-0.31053955]\n",
      " [-0.30744971]\n",
      " [-0.30435987]\n",
      " [-0.30127003]\n",
      " [-0.29818019]\n",
      " [-0.29509035]\n",
      " [-0.29200051]\n",
      " [-0.28891067]\n",
      " [-0.28582084]\n",
      " [-0.282731  ]\n",
      " [-0.27964116]\n",
      " [-0.27655132]\n",
      " [-0.27346148]\n",
      " [-0.27037164]\n",
      " [-0.2672818 ]\n",
      " [-0.26419196]\n",
      " [-0.26110212]\n",
      " [-0.25801228]\n",
      " [-0.25492244]\n",
      " [-0.2518326 ]\n",
      " [-0.24874276]\n",
      " [-0.24565292]\n",
      " [-0.24256308]\n",
      " [-0.23947325]\n",
      " [-0.23638341]\n",
      " [-0.23329357]\n",
      " [-0.23020373]\n",
      " [-0.22711389]\n",
      " [-0.22402405]\n",
      " [-0.22093421]\n",
      " [-0.21784437]\n",
      " [-0.21475453]\n",
      " [-0.21166469]\n",
      " [-0.20857485]\n",
      " [-0.20548501]\n",
      " [-0.20239517]\n",
      " [-0.19930533]\n",
      " [-0.19621549]\n",
      " [-0.19312566]\n",
      " [-0.19003582]\n",
      " [-0.18694598]\n",
      " [-0.18385614]\n",
      " [-0.1807663 ]\n",
      " [-0.17767646]\n",
      " [-0.17458662]\n",
      " [-0.17149678]\n",
      " [-0.16840694]\n",
      " [-0.1653171 ]\n",
      " [-0.16222726]\n",
      " [-0.15913742]\n",
      " [-0.15604758]\n",
      " [-0.15295774]\n",
      " [-0.1498679 ]\n",
      " [-0.14677807]\n",
      " [-0.14368823]\n",
      " [-0.14059839]\n",
      " [-0.13750855]\n",
      " [-0.13441871]\n",
      " [-0.13132887]\n",
      " [-0.12823903]\n",
      " [-0.12514919]\n",
      " [-0.12205935]\n",
      " [-0.11896951]\n",
      " [-0.11587967]\n",
      " [-0.11278983]\n",
      " [-0.10969999]\n",
      " [-0.10661015]\n",
      " [-0.10352031]\n",
      " [-0.10043048]\n",
      " [-0.09734064]\n",
      " [-0.0942508 ]\n",
      " [-0.09116096]\n",
      " [-0.08807112]\n",
      " [-0.08498128]\n",
      " [-0.08189144]\n",
      " [-0.0788016 ]\n",
      " [-0.07571176]\n",
      " [-0.07262192]\n",
      " [-0.06953208]\n",
      " [-0.06644224]\n",
      " [-0.0633524 ]\n",
      " [-0.06026256]\n",
      " [-0.05717272]\n",
      " [-0.05408289]\n",
      " [-0.05099305]\n",
      " [-0.04790321]\n",
      " [-0.04481337]\n",
      " [-0.04172353]\n",
      " [-0.03863369]\n",
      " [-0.03554385]\n",
      " [-0.03245401]\n",
      " [-0.02936417]\n",
      " [-0.02627433]\n",
      " [-0.02318449]\n",
      " [-0.02009465]\n",
      " [-0.01700481]\n",
      " [-0.01391497]\n",
      " [-0.01082513]\n",
      " [-0.0077353 ]\n",
      " [-0.00464546]\n",
      " [-0.00155562]\n",
      " [ 0.00153422]\n",
      " [ 0.00462406]\n",
      " [ 0.0077139 ]\n",
      " [ 0.01080374]\n",
      " [ 0.01389358]\n",
      " [ 0.01698342]\n",
      " [ 0.02007326]\n",
      " [ 0.0231631 ]\n",
      " [ 0.02625294]\n",
      " [ 0.02934278]\n",
      " [ 0.03243262]\n",
      " [ 0.03552246]\n",
      " [ 0.03861229]\n",
      " [ 0.04170213]\n",
      " [ 0.04479197]\n",
      " [ 0.04788181]\n",
      " [ 0.05097165]\n",
      " [ 0.05406149]\n",
      " [ 0.05715133]\n",
      " [ 0.06024117]\n",
      " [ 0.06333101]\n",
      " [ 0.06642085]\n",
      " [ 0.06951069]\n",
      " [ 0.07260053]\n",
      " [ 0.07569037]\n",
      " [ 0.07878021]\n",
      " [ 0.08187005]\n",
      " [ 0.08495988]\n",
      " [ 0.08804972]\n",
      " [ 0.09113956]\n",
      " [ 0.0942294 ]\n",
      " [ 0.09731924]\n",
      " [ 0.10040908]\n",
      " [ 0.10349892]\n",
      " [ 0.10658876]\n",
      " [ 0.1096786 ]\n",
      " [ 0.11276844]\n",
      " [ 0.11585828]\n",
      " [ 0.11894812]\n",
      " [ 0.12203796]\n",
      " [ 0.1251278 ]\n",
      " [ 0.12821764]\n",
      " [ 0.13130747]\n",
      " [ 0.13439731]\n",
      " [ 0.13748715]\n",
      " [ 0.14057699]\n",
      " [ 0.14366683]\n",
      " [ 0.14675667]\n",
      " [ 0.14984651]\n",
      " [ 0.15293635]\n",
      " [ 0.15602619]\n",
      " [ 0.15911603]\n",
      " [ 0.16220587]\n",
      " [ 0.16529571]\n",
      " [ 0.16838555]\n",
      " [ 0.17147539]\n",
      " [ 0.17456523]\n",
      " [ 0.17765506]\n",
      " [ 0.1807449 ]\n",
      " [ 0.18383474]\n",
      " [ 0.18692458]\n",
      " [ 0.19001442]\n",
      " [ 0.19310426]\n",
      " [ 0.1961941 ]\n",
      " [ 0.19928394]\n",
      " [ 0.20237378]\n",
      " [ 0.20546362]\n",
      " [ 0.20855346]\n",
      " [ 0.2116433 ]\n",
      " [ 0.21473314]\n",
      " [ 0.21782298]\n",
      " [ 0.22091282]\n",
      " [ 0.22400265]\n",
      " [ 0.22709249]\n",
      " [ 0.23018233]\n",
      " [ 0.23327217]\n",
      " [ 0.23636201]\n",
      " [ 0.23945185]\n",
      " [ 0.24254169]\n",
      " [ 0.24563153]\n",
      " [ 0.24872137]\n",
      " [ 0.25181121]\n",
      " [ 0.25490105]\n",
      " [ 0.25799089]\n",
      " [ 0.26108073]\n",
      " [ 0.26417057]\n",
      " [ 0.26726041]\n",
      " [ 0.27035024]\n",
      " [ 0.27344008]\n",
      " [ 0.27652992]\n",
      " [ 0.27961976]\n",
      " [ 0.2827096 ]\n",
      " [ 0.28579944]\n",
      " [ 0.28888928]\n",
      " [ 0.29197912]\n",
      " [ 0.29506896]\n",
      " [ 0.2981588 ]\n",
      " [ 0.30124864]\n",
      " [ 0.30433848]\n",
      " [ 0.30742832]\n",
      " [ 0.31051816]\n",
      " [ 0.313608  ]\n",
      " [ 0.31669783]\n",
      " [ 0.31978767]\n",
      " [ 0.32287751]\n",
      " [ 0.32596735]\n",
      " [ 0.32905719]\n",
      " [ 0.33214703]\n",
      " [ 0.33523687]\n",
      " [ 0.33832671]\n",
      " [ 0.34141655]\n",
      " [ 0.34450639]\n",
      " [ 0.34759623]\n",
      " [ 0.35068607]\n",
      " [ 0.35377591]\n",
      " [ 0.35686575]\n",
      " [ 0.35995559]\n",
      " [ 0.36304542]\n",
      " [ 0.36613526]\n",
      " [ 0.3692251 ]\n",
      " [ 0.37231494]\n",
      " [ 0.37540478]\n",
      " [ 0.37849462]\n",
      " [ 0.38158446]\n",
      " [ 0.3846743 ]\n",
      " [ 0.38776414]\n",
      " [ 0.39085398]\n",
      " [ 0.39394382]\n",
      " [ 0.39703366]\n",
      " [ 0.4001235 ]\n",
      " [ 0.40321334]\n",
      " [ 0.40630318]\n",
      " [ 0.40939301]]\n",
      "[-0.3785160151819251, -0.3723363365142123, -0.3661566578464994, -0.35997697917878657, -0.3537973005110737, -0.34761762184336087, -0.341437943175648, -0.33525826450793517, -0.3290785858402223, -0.32289890717250946, -0.3167192285047966, -0.31053954983708376, -0.3043598711693709, -0.29818019250165806, -0.2920005138339452, -0.28582083516623236, -0.2796411564985195, -0.27346147783080665, -0.2672817991630938, -0.26110212049538095, -0.2549224418276681, -0.24874276315995525, -0.2425630844922424, -0.23638340582452955, -0.2302037271568167, -0.22402404848910384, -0.217844369821391, -0.21166469115367814, -0.2054850124859653, -0.19930533381825244, -0.1931256551505396, -0.18694597648282674, -0.18076629781511389, -0.17458661914740103, -0.16840694047968818, -0.16222726181197533, -0.15604758314426248, -0.14986790447654963, -0.14368822580883678, -0.13750854714112393, -0.13132886847341108, -0.12514918980569822, -0.11896951113798537, -0.11278983247027252, -0.10661015380255967, -0.10043047513484682, -0.09425079646713397, -0.08807111779942112, -0.08189143913170827, -0.07571176046399541, -0.06953208179628256, -0.06335240312856971, -0.05717272446085686, -0.05099304579314401, -0.04481336712543116, -0.03863368845771831, -0.032454009790005456, -0.026274331122292605, -0.020094652454579753, -0.013914973786866902, -0.007735295119154051, -0.0015556164514411996, 0.004624062216271652, 0.010803740883984503, 0.016983419551697354, 0.023163098219410205, 0.029342776887123057, 0.03552245555483591, 0.04170213422254876, 0.04788181289026161, 0.05406149155797446, 0.06024117022568731, 0.06642084889340016, 0.07260052756111302, 0.07878020622882587, 0.08495988489653872, 0.09113956356425157, 0.09731924223196442, 0.10349892089967727, 0.10967859956739012, 0.11585827823510297, 0.12203795690281583, 0.12821763557052868, 0.13439731423824153, 0.14057699290595438, 0.14675667157366723, 0.15293635024138008, 0.15911602890909293, 0.16529570757680578, 0.17147538624451863, 0.1776550649122315, 0.18383474357994434, 0.1900144222476572, 0.19619410091537004, 0.2023737795830829, 0.20855345825079574, 0.2147331369185086, 0.22091281558622144, 0.2270924942539343, 0.23327217292164715, 0.23945185158936, 0.24563153025707285, 0.2518112089247857, 0.25799088759249855, 0.2641705662602114, 0.27035024492792425, 0.2765299235956371, 0.28270960226334996, 0.2888892809310628, 0.29506895959877566, 0.3012486382664885, 0.30742831693420136, 0.3136079956019142, 0.31978767426962706, 0.3259673529373399, 0.33214703160505277, 0.3383267102727656, 0.34450638894047847, 0.3506860676081913, 0.35686574627590417, 0.363045424943617, 0.3692251036113299, 0.3754047822790427, 0.3815844609467556, 0.38776413961446843, 0.3939438182821813, 0.40012349694989413, 0.406303175617607, 0.41248285428531983, 0.4186625329530327, 0.42484221162074554, 0.4310218902884584, 0.43720156895617124, 0.4433812476238841, 0.44956092629159694, 0.4557406049593098, 0.46192028362702264, 0.4680999622947355, 0.47427964096244835, 0.4804593196301612, 0.48663899829787405, 0.4928186769655869, 0.49899835563329975, 0.5051780343010126, 0.5113577129687255, 0.5175373916364383, 0.5237170703041512, 0.529896748971864, 0.5360764276395769, 0.5422561063072897, 0.5484357849750026, 0.5546154636427154, 0.5607951423104283, 0.5669748209781411, 0.573154499645854, 0.5793341783135668, 0.5855138569812797, 0.5916935356489925, 0.5978732143167054, 0.6040528929844182, 0.6102325716521311, 0.6164122503198439, 0.6225919289875568, 0.6287716076552696, 0.6349512863229825, 0.6411309649906953, 0.6473106436584082, 0.653490322326121, 0.6596700009938339, 0.6658496796615467, 0.6720293583292596, 0.6782090369969724, 0.6843887156646853, 0.6905683943323981, 0.696748073000111, 0.7029277516678238, 0.7091074303355367, 0.7152871090032495, 0.7214667876709624, 0.7276464663386752, 0.7338261450063881, 0.740005823674101, 0.7461855023418138, 0.7523651810095267, 0.7585448596772395, 0.7647245383449524, 0.7709042170126652, 0.7770838956803781, 0.7832635743480909, 0.7894432530158038, 0.7956229316835166, 0.8018026103512295, 0.8079822890189423, 0.8141619676866552, 0.820341646354368, 0.8265213250220809, 0.8327010036897937, 0.8388806823575066, 0.8450603610252194, 0.8512400396929323, 0.8574197183606451, 0.863599397028358, 0.8697790756960708, 0.8759587543637837, 0.8821384330314965, 0.8883181116992094, 0.8944977903669222, 0.9006774690346351, 0.9068571477023479, 0.9130368263700608, 0.9192165050377736, 0.9253961837054865, 0.9315758623731993, 0.9377555410409122, 0.943935219708625, 0.9501148983763379, 0.9562945770440507, 0.9624742557117636, 0.9686539343794764, 0.9748336130471893, 0.9810132917149021, 0.987192970382615, 0.9933726490503278, 0.9995523277180407, 1.0057320063857536, 1.0119116850534664, 1.0180913637211793, 1.024271042388892, 1.030450721056605, 1.0366303997243178, 1.0428100783920307, 1.0489897570597435, 1.0551694357274564, 1.0613491143951692, 1.067528793062882, 1.073708471730595, 1.0798881503983078, 1.0860678290660206, 1.0922475077337335, 1.0984271864014463, 1.1046068650691592, 1.110786543736872, 1.1169662224045849, 1.1231459010722977, 1.1293255797400106, 1.1355052584077234, 1.1416849370754363, 1.1478646157431491, 1.154044294410862, 1.1602239730785748, 1.1664036517462877, 1.1725833304140005, 1.1787630090817134, 1.1849426877494262, 1.191122366417139, 1.197302045084852]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": " did not return arithmetic sequence: [-0.3785160151819251, -0.3723363365142123, -0.3661566578464994, -0.35997697917878657, -0.3568871398449301, -0.34761762184336087, -0.3414379431756479, -0.33525826450793517, -0.3290785858402222, -0.32289890717250946, -0.3167192285047966, -0.31053954983708376, -0.3043598711693709, -0.29818019250165806, -0.2920005138339452, -0.28582083516623213, -0.2796411564985195, -0.27346147783080665, -0.2672817991630938, -0.26110212049538095, -0.2549224418276681, -0.24874276315995525, -0.2425630844922424, -0.2363834058245292, -0.2302037271568167, -0.22711388782295994, -0.217844369821391, -0.21166469115367814, -0.2054850124859653, -0.19930533381825244, -0.1931256551505396, -0.18694597648282674, -0.18076629781511389, -0.17458661914740103, -0.1684069404796877, -0.16222726181197533, -0.15604758314426248, -0.14986790447654963, -0.14368822580883625, -0.13750854714112393, -0.13132886847341108, -0.1282390291395541, -0.11896951113798479, -0.11278983247027252, -0.10661015380255967, -0.10043047513484682, -0.09425079646713397, -0.08807111779942045, -0.0818914391317076, -0.07571176046399541, -0.06953208179628256, -0.06335240312856899, -0.05717272446085686, -0.05099304579314401, -0.04481336712543038, -0.03863368845771831, -0.032454009790005456, -0.026274331122292605, -0.023184491788435402, -0.017004813120722495, -0.007735295119153218, -0.0015556164514411996, 0.004624062216271652, 0.010803740883984503, 0.013893580217841817, 0.020073258885554668, 0.029342776887123057, 0.03552245555483591, 0.04170213422254876, 0.04788181289026161, 0.05406149155797446, 0.06024117022568831, 0.06642084889340116, 0.07260052756111302, 0.07878020622882587, 0.08495988489653872, 0.0880497242303962, 0.09731924223196547, 0.10349892089967727, 0.10967859956739123, 0.11585827823510297, 0.11894811756896051, 0.1282176355705298, 0.13439731423824264, 0.14057699290595554, 0.14675667157366723, 0.14984651090752488, 0.15911602890909415, 0.16529570757680578, 0.17147538624451863, 0.17456522557837628, 0.18383474357994434, 0.1900144222476572, 0.19310426158151495, 0.2023737795830829, 0.20855345825079574, 0.21473313691850993, 0.22091281558622278, 0.2270924942539343, 0.23327217292164715, 0.23945185158936, 0.24254169092321787, 0.2518112089247857, 0.25799088759249855, 0.2641705662602114, 0.27035024492792425, 0.27652992359563855, 0.28270960226334996, 0.2888892809310628, 0.29506895959877566, 0.3012486382664885, 0.30742831693420136, 0.31360799560191577, 0.31978767426962706, 0.3259673529373399, 0.33214703160505277, 0.3383267102727656, 0.34450638894047847, 0.3506860676081913, 0.35686574627590417, 0.35995558560976226, 0.3692251036113299, 0.3754047822790427, 0.3815844609467556, 0.3877641396144702, 0.39394381828218306, 0.40012349694989413, 0.40321333628375233, 0.41248285428531983, 0.4186625329530327, 0.42484221162074554, 0.4310218902884584, 0.43720156895617124, 0.4433812476238841, 0.44956092629159694, 0.4557406049593098, 0.46192028362702264, 0.4680999622947355, 0.47427964096244835, 0.4804593196301612, 0.48663899829787405, 0.4928186769655869, 0.49899835563329975, 0.5051780343010126, 0.5113577129687255, 0.5175373916364383, 0.5237170703041512, 0.529896748971864, 0.5360764276395769, 0.5422561063072897, 0.5484357849750026, 0.5546154636427154, 0.5607951423104283, 0.5669748209781411, 0.573154499645854, 0.5793341783135668, 0.5855138569812797, 0.5916935356489925, 0.5978732143167054, 0.6040528929844182, 0.6102325716521311, 0.6164122503198439, 0.6225919289875568, 0.6287716076552696, 0.6349512863229825, 0.6411309649906953, 0.6473106436584082, 0.653490322326121, 0.6596700009938339, 0.6658496796615467, 0.6720293583292596, 0.6782090369969724, 0.6843887156646853, 0.6905683943323981, 0.696748073000111, 0.7029277516678238, 0.7091074303355367, 0.7152871090032495, 0.7214667876709624, 0.7276464663386752, 0.7338261450063881, 0.740005823674101, 0.7461855023418138, 0.7523651810095267, 0.7585448596772395, 0.7647245383449524, 0.7709042170126652, 0.7770838956803781, 0.7832635743480909, 0.7894432530158038, 0.7956229316835166, 0.8018026103512295, 0.8079822890189423, 0.8141619676866552, 0.820341646354368, 0.8265213250220809, 0.8327010036897937, 0.8388806823575066, 0.8450603610252194, 0.8512400396929323, 0.8574197183606451, 0.863599397028358, 0.8697790756960708, 0.8759587543637837, 0.8821384330314965, 0.8883181116992094, 0.8944977903669222, 0.9006774690346351, 0.9068571477023479, 0.9130368263700608, 0.9192165050377736, 0.9253961837054865, 0.9315758623731993, 0.9377555410409122, 0.943935219708625, 0.9501148983763379, 0.9562945770440507, 0.9624742557117636, 0.9686539343794764, 0.9748336130471893, 0.9810132917149021, 0.987192970382615, 0.9933726490503278, 0.9995523277180407, 1.0057320063857536, 1.0119116850534664, 1.0180913637211793, 1.024271042388892, 1.030450721056605, 1.0366303997243178, 1.0428100783920307, 1.0489897570597435, 1.0551694357274564, 1.0613491143951692, 1.067528793062882, 1.073708471730595, 1.0798881503983078, 1.0860678290660206, 1.0922475077337335, 1.0984271864014463, 1.1046068650691592, 1.110786543736872, 1.1169662224045849, 1.1231459010722977, 1.1293255797400106, 1.1355052584077234, 1.1416849370754363, 1.1478646157431491, 1.154044294410862, 1.1602239730785748, 1.1664036517462877, 1.1725833304140005, 1.1787630090817134, 1.1849426877494262, 1.191122366417139, 1.197302045084852], from vlaues [-0.37851602 -0.35688714 -0.34143794 -0.32907859 -0.28582084 -0.23638341\n -0.22711389 -0.16840694 -0.14368823 -0.12823903 -0.11896951 -0.08807112\n -0.08189144 -0.0633524  -0.04481337 -0.02318449 -0.01700481 -0.0077353\n  0.01389358  0.02007326  0.06024117  0.06642085  0.08804972  0.09731924\n  0.1096786   0.11894812  0.12821764  0.13439731  0.14057699  0.14984651\n  0.15911603  0.17456523  0.19310426  0.21473314  0.22091282  0.24254169\n  0.27652992  0.313608    0.35995559  0.38776414  0.39394382  0.40321334]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m X, y \u001B[38;5;241m=\u001B[39m gen_nonlinear_data(\u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m40\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m test_loss, loss_grid, iters_grid, times_grid, test_loss_uncoded, uncoded_times \u001B[38;5;241m=\u001B[39m run(X,y, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonlinear_data.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[1], line 97\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(X, y, filename)\u001B[0m\n\u001B[1;32m     95\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     96\u001B[0m \u001B[38;5;66;03m#w, num_iters = grdescentquant(func, w0, stepsize, maxiter, Master, w_lvl, grd_lvl, X, y, filename, tolerance=1e-02)\u001B[39;00m\n\u001B[0;32m---> 97\u001B[0m w, num_iters \u001B[38;5;241m=\u001B[39m grdescentquant(func, w0, stepsize, maxiter, Master, w_lvl, grd_lvl, X, y, filename, \u001B[38;5;241m1e-02\u001B[39m)\n\u001B[1;32m     98\u001B[0m \u001B[38;5;66;03m# grdescentquant(func, w, stepsize, maxiter, Master, w_lvl, grd_lvl, X, y, filename, tolerance)\u001B[39;00m\n\u001B[1;32m    100\u001B[0m end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[0;32m~/Desktop/research/low_access-merge_tql/logistic_regression/GrdDscntQuant.py:43\u001B[0m, in \u001B[0;36mgrdescentquant\u001B[0;34m(func, w, stepsize, maxiter, Master, w_lvl, grd_lvl, X, y, filename, tolerance)\u001B[0m\n\u001B[1;32m     31\u001B[0m w, index \u001B[38;5;241m=\u001B[39m quantize(w, w_lvl, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munif\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mdict\u001B[39m \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw-quantization\u001B[39m\u001B[38;5;124m'\u001B[39m: [w_lvl],\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrd-quantization\u001B[39m\u001B[38;5;124m'\u001B[39m: [grd_lvl],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     41\u001B[0m \n\u001B[1;32m     42\u001B[0m     } \u001B[38;5;66;03m# for data collection I think\u001B[39;00m\n\u001B[0;32m---> 43\u001B[0m loss, gradient \u001B[38;5;241m=\u001B[39m func(w, Master, w_lvl, grd_lvl, \u001B[38;5;28mdict\u001B[39m, X, y, filename, index)\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m loss \u001B[38;5;241m>\u001B[39m prior_loss:\n\u001B[1;32m     46\u001B[0m     w \u001B[38;5;241m=\u001B[39m w \u001B[38;5;241m+\u001B[39m stepsize \u001B[38;5;241m*\u001B[39m prior_gradient\n",
      "File \u001B[0;32m~/Desktop/research/low_access-merge_tql/logistic_regression/quant_logistic.py:25\u001B[0m, in \u001B[0;36mquant_logistic\u001B[0;34m(w, Master, w_lvl, grd_lvl, dict, X, y, filename, index)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mquant_logistic\u001B[39m(w, Master, w_lvl, grd_lvl, \u001B[38;5;28mdict\u001B[39m, X, y, filename, index):\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;66;03m#y_pred = w.T @ xTr ... now with low access\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m Master\u001B[38;5;241m.\u001B[39muniform_query(w, w_lvl, \u001B[38;5;28mdict\u001B[39m, X, index)\n\u001B[1;32m     26\u001B[0m     vals \u001B[38;5;241m=\u001B[39m y \u001B[38;5;241m*\u001B[39m y_pred\n\u001B[1;32m     27\u001B[0m     loss \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(np\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mvals)))\n",
      "File \u001B[0;32m~/Desktop/research/low_access-merge_tql/coded_computation/master.py:162\u001B[0m, in \u001B[0;36mmaster.uniform_query\u001B[0;34m(self, w, lvl, dict, X, index)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse, actual \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, np\u001B[38;5;241m.\u001B[39mhstack((response\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m5\u001B[39m], actual\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m5\u001B[39m])), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex passed: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mindex\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 162\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow we used to make the index: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimpute(values,\u001B[38;5;250m \u001B[39mexpected_len,\u001B[38;5;250m \u001B[39m\u001B[38;5;28mdict\u001B[39m)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtabel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery_table\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery does not work: from w = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp\u001B[38;5;241m.\u001B[39munique(w_flat)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, with error: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, shape :\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mw\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/research/low_access-merge_tql/coded_computation/impute.py:38\u001B[0m, in \u001B[0;36mimpute\u001B[0;34m(values, expected_len, dict)\u001B[0m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m returned incomplete list\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_approx_arithmetic_sequence(expected_index, tolerance\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-6\u001B[39m):\n\u001B[0;32m---> 38\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m did not return arithmetic sequence: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexpected_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, from vlaues \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalues\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(expected_index)\n",
      "\u001B[0;31mValueError\u001B[0m:  did not return arithmetic sequence: [-0.3785160151819251, -0.3723363365142123, -0.3661566578464994, -0.35997697917878657, -0.3568871398449301, -0.34761762184336087, -0.3414379431756479, -0.33525826450793517, -0.3290785858402222, -0.32289890717250946, -0.3167192285047966, -0.31053954983708376, -0.3043598711693709, -0.29818019250165806, -0.2920005138339452, -0.28582083516623213, -0.2796411564985195, -0.27346147783080665, -0.2672817991630938, -0.26110212049538095, -0.2549224418276681, -0.24874276315995525, -0.2425630844922424, -0.2363834058245292, -0.2302037271568167, -0.22711388782295994, -0.217844369821391, -0.21166469115367814, -0.2054850124859653, -0.19930533381825244, -0.1931256551505396, -0.18694597648282674, -0.18076629781511389, -0.17458661914740103, -0.1684069404796877, -0.16222726181197533, -0.15604758314426248, -0.14986790447654963, -0.14368822580883625, -0.13750854714112393, -0.13132886847341108, -0.1282390291395541, -0.11896951113798479, -0.11278983247027252, -0.10661015380255967, -0.10043047513484682, -0.09425079646713397, -0.08807111779942045, -0.0818914391317076, -0.07571176046399541, -0.06953208179628256, -0.06335240312856899, -0.05717272446085686, -0.05099304579314401, -0.04481336712543038, -0.03863368845771831, -0.032454009790005456, -0.026274331122292605, -0.023184491788435402, -0.017004813120722495, -0.007735295119153218, -0.0015556164514411996, 0.004624062216271652, 0.010803740883984503, 0.013893580217841817, 0.020073258885554668, 0.029342776887123057, 0.03552245555483591, 0.04170213422254876, 0.04788181289026161, 0.05406149155797446, 0.06024117022568831, 0.06642084889340116, 0.07260052756111302, 0.07878020622882587, 0.08495988489653872, 0.0880497242303962, 0.09731924223196547, 0.10349892089967727, 0.10967859956739123, 0.11585827823510297, 0.11894811756896051, 0.1282176355705298, 0.13439731423824264, 0.14057699290595554, 0.14675667157366723, 0.14984651090752488, 0.15911602890909415, 0.16529570757680578, 0.17147538624451863, 0.17456522557837628, 0.18383474357994434, 0.1900144222476572, 0.19310426158151495, 0.2023737795830829, 0.20855345825079574, 0.21473313691850993, 0.22091281558622278, 0.2270924942539343, 0.23327217292164715, 0.23945185158936, 0.24254169092321787, 0.2518112089247857, 0.25799088759249855, 0.2641705662602114, 0.27035024492792425, 0.27652992359563855, 0.28270960226334996, 0.2888892809310628, 0.29506895959877566, 0.3012486382664885, 0.30742831693420136, 0.31360799560191577, 0.31978767426962706, 0.3259673529373399, 0.33214703160505277, 0.3383267102727656, 0.34450638894047847, 0.3506860676081913, 0.35686574627590417, 0.35995558560976226, 0.3692251036113299, 0.3754047822790427, 0.3815844609467556, 0.3877641396144702, 0.39394381828218306, 0.40012349694989413, 0.40321333628375233, 0.41248285428531983, 0.4186625329530327, 0.42484221162074554, 0.4310218902884584, 0.43720156895617124, 0.4433812476238841, 0.44956092629159694, 0.4557406049593098, 0.46192028362702264, 0.4680999622947355, 0.47427964096244835, 0.4804593196301612, 0.48663899829787405, 0.4928186769655869, 0.49899835563329975, 0.5051780343010126, 0.5113577129687255, 0.5175373916364383, 0.5237170703041512, 0.529896748971864, 0.5360764276395769, 0.5422561063072897, 0.5484357849750026, 0.5546154636427154, 0.5607951423104283, 0.5669748209781411, 0.573154499645854, 0.5793341783135668, 0.5855138569812797, 0.5916935356489925, 0.5978732143167054, 0.6040528929844182, 0.6102325716521311, 0.6164122503198439, 0.6225919289875568, 0.6287716076552696, 0.6349512863229825, 0.6411309649906953, 0.6473106436584082, 0.653490322326121, 0.6596700009938339, 0.6658496796615467, 0.6720293583292596, 0.6782090369969724, 0.6843887156646853, 0.6905683943323981, 0.696748073000111, 0.7029277516678238, 0.7091074303355367, 0.7152871090032495, 0.7214667876709624, 0.7276464663386752, 0.7338261450063881, 0.740005823674101, 0.7461855023418138, 0.7523651810095267, 0.7585448596772395, 0.7647245383449524, 0.7709042170126652, 0.7770838956803781, 0.7832635743480909, 0.7894432530158038, 0.7956229316835166, 0.8018026103512295, 0.8079822890189423, 0.8141619676866552, 0.820341646354368, 0.8265213250220809, 0.8327010036897937, 0.8388806823575066, 0.8450603610252194, 0.8512400396929323, 0.8574197183606451, 0.863599397028358, 0.8697790756960708, 0.8759587543637837, 0.8821384330314965, 0.8883181116992094, 0.8944977903669222, 0.9006774690346351, 0.9068571477023479, 0.9130368263700608, 0.9192165050377736, 0.9253961837054865, 0.9315758623731993, 0.9377555410409122, 0.943935219708625, 0.9501148983763379, 0.9562945770440507, 0.9624742557117636, 0.9686539343794764, 0.9748336130471893, 0.9810132917149021, 0.987192970382615, 0.9933726490503278, 0.9995523277180407, 1.0057320063857536, 1.0119116850534664, 1.0180913637211793, 1.024271042388892, 1.030450721056605, 1.0366303997243178, 1.0428100783920307, 1.0489897570597435, 1.0551694357274564, 1.0613491143951692, 1.067528793062882, 1.073708471730595, 1.0798881503983078, 1.0860678290660206, 1.0922475077337335, 1.0984271864014463, 1.1046068650691592, 1.110786543736872, 1.1169662224045849, 1.1231459010722977, 1.1293255797400106, 1.1355052584077234, 1.1416849370754363, 1.1478646157431491, 1.154044294410862, 1.1602239730785748, 1.1664036517462877, 1.1725833304140005, 1.1787630090817134, 1.1849426877494262, 1.191122366417139, 1.197302045084852], from vlaues [-0.37851602 -0.35688714 -0.34143794 -0.32907859 -0.28582084 -0.23638341\n -0.22711389 -0.16840694 -0.14368823 -0.12823903 -0.11896951 -0.08807112\n -0.08189144 -0.0633524  -0.04481337 -0.02318449 -0.01700481 -0.0077353\n  0.01389358  0.02007326  0.06024117  0.06642085  0.08804972  0.09731924\n  0.1096786   0.11894812  0.12821764  0.13439731  0.14057699  0.14984651\n  0.15911603  0.17456523  0.19310426  0.21473314  0.22091282  0.24254169\n  0.27652992  0.313608    0.35995559  0.38776414  0.39394382  0.40321334]"
     ]
    }
   ],
   "source": [
    "X, y = gen_nonlinear_data(500, 40, 1)\n",
    "\n",
    "test_loss, loss_grid, iters_grid, times_grid, test_loss_uncoded, uncoded_times = run(X,y, \"nonlinear_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = gen_data(500, 40, 1)\n",
    "test_loss1, loss_grid1, iters_grid1, times_grid1, test_loss_uncoded1, uncoded_times1 = run(X,y, \"linear_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = arff.loadarff('/Users/willem/Downloads/speeddating.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "hill_train_x, hill_test_x, hill_train_y, hill_test_y = clean_and_scale(df, \"match\")\n",
    "hill_train_x, hill_train_y = pad(hill_train_x, hill_train_y, 7)\n",
    "hill_test_x, hill_test_y = pad(hill_test_x, hill_test_y, 7)\n",
    "\n",
    "print(hill_train_x.shape, hill_train_y.shape, hill_test_x.shape, hill_test_y.shape)\n",
    "\n",
    "X = np.vstack((hill_test_x,hill_train_x))\n",
    "y = np.vstack((hill_test_y, hill_train_y))\n",
    "test_loss_real, loss_grid_real, iters_grid_real, times_grid_real, test_loss_uncoded_real, uncoded_times_real  = run(X,y, \"real_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_data import gen_seperable_data\n",
    "X, y, w = gen_seperable_data(500, 40)\n",
    "\n",
    "test_loss, loss_grid, iters_grid, times_grid, test_loss_uncoded, uncoded_times = run(X,y, \"seperable_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = gen_nonlinear_data(2000, 200, 1)\n",
    "\n",
    "test_loss, loss_grid, iters_grid, times_grid, test_loss_uncoded, uncoded_times = run(X,y, \"hdnonlinear_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_bar(data):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    rows, cols = data.shape\n",
    "    x, y = np.meshgrid(np.arange(cols), np.arange(rows))\n",
    "\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    z = np.zeros_like(x)\n",
    "\n",
    "    dz = data.flatten()\n",
    "\n",
    "    ax.bar3d(x, y, z, 1, 1, dz, shade=True)\n",
    "\n",
    "    ax.set_xlabel('w_lvl')\n",
    "    ax.set_ylabel('grd_lvl')\n",
    "    ax.set_zlabel('z')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_per_query(df):\n",
    "    import numpy as np\n",
    "\n",
    "    df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    grouped = df_numeric.groupby(['w-quantization', 'grd-quantization']).mean()\n",
    "\n",
    "    # Reset the index to make plotting easier\n",
    "    grouped = grouped.reset_index()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    # Setting up the figure and 3D axis\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Data for the bars\n",
    "    x = grouped['w-quantization']\n",
    "    y = grouped['grd-quantization']\n",
    "    z = grouped['time']  # or any other column you wish to visualize\n",
    "\n",
    "    # The bar positions and width\n",
    "    dx = dy = 0.5\n",
    "    dz = z\n",
    "\n",
    "    ax.bar3d(x, y, [0]*len(z), dx, dy, dz, color='b')\n",
    "\n",
    "    # Labeling the axes\n",
    "    ax.set_xlabel('w-quantization')\n",
    "    ax.set_ylabel('grd-quantization')\n",
    "    ax.set_zlabel('Average Time Per Query')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'access_measurements.csv'\n",
    "\n",
    "column_names = [\n",
    "    'w-quantization', 'grd-quantization', 'imputation', 'access',\n",
    "    'query type', 'time', 'stop cond', 'iters'\n",
    "]\n",
    "\n",
    "df_nonlinear = pd.read_csv(file_path, header=None, names=column_names)\n",
    "\n",
    "print(df_nonlinear.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.02223896941294333\n",
      "\n",
      " 0.02223896941294333\n",
      "\n",
      " 0.02223896941294333\n",
      "\n",
      " 0.022238969412943226\n",
      "\n",
      " 0.022238969412943434\n",
      "\n",
      " 0.03335845411941482\n",
      "\n",
      " 0.02223896941294333\n",
      "\n",
      " 0.011119484706471838\n",
      "\n",
      " 0.022238969412943344\n",
      "\n",
      " 0.022238969412943316\n",
      "\n",
      " 0.022238969412943316\n",
      "\n",
      " 0.022238969412943344\n",
      "\n",
      " 0.022238969412943344\n",
      "\n",
      " 0.022238969412943288\n",
      "\n",
      " 0.022238969412943344\n"
     ]
    }
   ],
   "source": [
    "bad_w = [-0.08605444406989449, -0.06381547465695116, -0.04157650524400783, -0.019337535831064498, 0.0029014335818787276, 0.02514040299482216, 0.05849885711423698, 0.08073782652718031\n",
    "         , 0.09185731123365215, 0.1140962806465955, 0.1363352500595388, 0.15857421947248213, 0.18081318888542547, 0.2030521582983688, 0.2252911277113121, 0.24753009712425544]\n",
    "\n",
    "for i in range(1,len(bad_w)):\n",
    "    print(f\"\\n {bad_w[i] - bad_w[i-1]}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
