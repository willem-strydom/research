{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 45) (500, 1)\n",
      "(400, 45) (400, 1)\n",
      "(100, 45) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from logistic_regression.GrdDscntQuant import grdescentquant\n",
    "from logistic_regression.normal_logistic import normallogistic\n",
    "from logistic_regression.GrdDscnt import grdescentnormal\n",
    "from logistic_regression.quant_logistic import quant_logistic\n",
    "from logistic_regression.GrdDscntUncoded import grdescentuncoded\n",
    "from logistic_regression.uncoded_logistic import  uncoded_logistic\n",
    "from quantization.quantize import quantize\n",
    "from coded_computation.master import master\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from pad_and_clean import pad\n",
    "from pad_and_clean import clean_and_scale\n",
    "import time\n",
    "from gen_data import gen_seperable_data, gen_margin_seperable_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from run_test import run\n",
    "\n",
    "# do runs, make plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperable data #1\n",
    "X,y,w = gen_seperable_data(800,100)\n",
    "\n",
    "run(X,y,\"seperable1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperable data #2\n",
    "X,y,w = gen_seperable_data(800,50)\n",
    "\n",
    "run(X,y,\"seperable2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss from unquantized logistic regresison: 0.23809523809523808 on 37 iterations in 0.005783796310424805 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# margined seperable data #1\u001B[39;00m\n\u001B[1;32m      3\u001B[0m X,y,w \u001B[38;5;241m=\u001B[39m gen_margin_seperable_data(\u001B[38;5;241m100\u001B[39m,\u001B[38;5;241m10\u001B[39m,\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m run(X,y,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_data.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/research/low_access-merge_tql/run_test.py:57\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(X, y, filename)\u001B[0m\n\u001B[1;32m     54\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m grd_lvl \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m4\u001B[39m):\n\u001B[1;32m     56\u001B[0m             w0 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, (X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m---> 57\u001B[0m             w, num_iters \u001B[38;5;241m=\u001B[39m grdescentquant(func, w0, stepsize, maxiter, Master, w_lvl, grd_lvl, X, y, filename, \u001B[38;5;241m1e-02\u001B[39m, Xt,yt)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/research/low_access-merge_tql/logistic_regression/GrdDscntQuant.py:45\u001B[0m, in \u001B[0;36mgrdescentquant\u001B[0;34m(func, w, stepsize, maxiter, Master, w_lvl, grd_lvl, X, y, filename, tolerance, Xt, yt)\u001B[0m\n\u001B[1;32m     32\u001B[0m w, index \u001B[38;5;241m=\u001B[39m quantize(w, w_lvl, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munif\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28mdict\u001B[39m \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw-quantization\u001B[39m\u001B[38;5;124m'\u001B[39m: [w_lvl],\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrd-quantization\u001B[39m\u001B[38;5;124m'\u001B[39m: [grd_lvl],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124me out\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     44\u001B[0m }\n\u001B[0;32m---> 45\u001B[0m loss, gradient \u001B[38;5;241m=\u001B[39m func(w, Master, w_lvl, grd_lvl, \u001B[38;5;28mdict\u001B[39m, X, y, filename, index)\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m loss \u001B[38;5;241m>\u001B[39m prior_loss:\n\u001B[1;32m     48\u001B[0m     w \u001B[38;5;241m=\u001B[39m w \u001B[38;5;241m+\u001B[39m stepsize \u001B[38;5;241m*\u001B[39m prior_gradient\n",
      "File \u001B[0;32m~/Desktop/research/low_access-merge_tql/logistic_regression/quant_logistic.py:22\u001B[0m, in \u001B[0;36mquant_logistic\u001B[0;34m(w, Master, w_lvl, grd_lvl, dict, X, y, filename, index)\u001B[0m\n\u001B[1;32m     20\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m Master\u001B[38;5;241m.\u001B[39muniform_query(w, w_lvl, \u001B[38;5;28mdict\u001B[39m, X, index)\n\u001B[1;32m     21\u001B[0m vals \u001B[38;5;241m=\u001B[39m y \u001B[38;5;241m*\u001B[39m y_pred\n\u001B[0;32m---> 22\u001B[0m loss \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(np\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mvals)))\n\u001B[1;32m     23\u001B[0m record_access(\u001B[38;5;28mdict\u001B[39m, filename)\n\u001B[1;32m     25\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39mexp(x))\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/cse314/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m   3461\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3462\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 3464\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _methods\u001B[38;5;241m.\u001B[39m_mean(a, axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m   3465\u001B[0m                       out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/cse314/lib/python3.11/site-packages/numpy/core/_methods.py:164\u001B[0m, in \u001B[0;36m_mean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    161\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _clip_dep_invoke_with_casting(\n\u001B[1;32m    162\u001B[0m             um\u001B[38;5;241m.\u001B[39mclip, a, \u001B[38;5;28mmin\u001B[39m, \u001B[38;5;28mmax\u001B[39m, out\u001B[38;5;241m=\u001B[39mout, casting\u001B[38;5;241m=\u001B[39mcasting, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 164\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_mean\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    165\u001B[0m     arr \u001B[38;5;241m=\u001B[39m asanyarray(a)\n\u001B[1;32m    167\u001B[0m     is_float16_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# margined seperable data #1\n",
    "\n",
    "X,y,w = gen_margin_seperable_data(800,100,1)\n",
    "\n",
    "run(X,y,\"marginal1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# margined sperable data #2\n",
    "\n",
    "X,y,w = gen_margin_seperable_data(800,50,1)\n",
    "\n",
    "run(X,y,\"marginal2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data #1\n",
    "\n",
    "data = arff.loadarff('/Users/willem/Downloads/speeddating.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "hill_train_x, hill_test_x, hill_train_y, hill_test_y = clean_and_scale(df, \"match\")\n",
    "hill_train_x, hill_train_y = pad(hill_train_x, hill_train_y, 7)\n",
    "hill_test_x, hill_test_y = pad(hill_test_x, hill_test_y, 7)\n",
    "\n",
    "print(hill_train_x.shape, hill_train_y.shape, hill_test_x.shape, hill_test_y.shape)\n",
    "\n",
    "X = np.vstack((hill_test_x,hill_train_x))\n",
    "y = np.vstack((hill_test_y, hill_train_y))\n",
    "run(X,y, \"real_data1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data #3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots produced below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add func to make heatmaps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want graphs that go like...\n",
    "\n",
    "# quantized system\n",
    "# unquantized system\n",
    "# the normalized difference between the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized e_in heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized e_out heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access but in a hand wavy manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time, maybe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
